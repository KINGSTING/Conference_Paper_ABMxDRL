%!TEX root = ../cs_conference_paper.tex

This study demonstrates that a Heuristic-Guided DRL agent can successfully optimize municipal waste segregation policies under strict budget constraints, discovering a ``Sequential Saturation'' strategy that outperforms status quo equitable distribution \cite{ZhengAI2022}. Global Sensitivity Analysis revealed that logistical friction, or the Cost of Effort ($c_{\text{effort}}$), is the primary barrier to compliance (accounting for 83\% of variance), indicating policies must prioritize convenience over pure awareness \cite{Yazawa2025}. Furthermore, the near-zero sensitivity of the Attitude ($w_a$) parameter highlights a profound ``Value-Action Gap,'' mathematically justifying the agent's pivot toward extrinsic motivators \cite{Zhao2022}. Ultimately, leveraging Social Norms ($w_{sn} \approx 0.35$) creates a self-sustaining ``Graduation Effect,'' allowing Local Government Units (LGUs) to build resilient compliance ecosystems without perpetual funding reliance \cite{Andre2021, Jimenez2025}.

Future research should focus on scaling this framework into a Multi-Agent Reinforcement Learning (MARL) environment, where individual barangays operate as autonomous, self-optimizing sub-agents negotiating for resources with the central LGU. Additionally, transitioning the ABM's observational state from delayed quarterly audits to real-time empirical data streams—such as IoT-enabled smart bin sensors or digitized waste collection routing—would allow the DRL agent to execute dynamic, micro-targeted policy interventions. Finally, incorporating the informal waste sector (e.g., independent scavengers and private recyclers) into the agent architecture would further enhance the ecological validity of the municipality's simulation.